# <center>实验二

## <center>使用Flume、Thrift、Kafka、HBase进行数据收集传输与存储













**班级：2018211310**

**学号：2018211527**

**姓名：陈泊任**

**时间：2021年4月6日**





<div STYLE="page-break-after: always;"></div>

[TOC]

<div STYLE="page-break-after: always;"></div>

### 一、实验目的：

1、掌握 Flume、Thrift、Kafka、HBase 的安装；

2、掌握 Flume、Thrift、Kafka、HBase 的使用。



### 二、实验平台：

操作系统：Ubuntu 18.04 LTS



### 三、实验内容

#### 1、下载相关软件

##### (1) Flume

版本：apache-flume-1.9.0

**① 下载**

地址：https://flume.apache.org/download.html

**② 解压**

在压缩包目录下解压

```shell
tar -zxvf apache-flume-1.9.0-bin.tar.gz
```

将解压文件移到flume-1.9.0文件里

```shell
mv apache-flume-1.9.0-bin flume-1.9.0
```

**③ 配置**

进入配置文件目录下

```shell
cd flume-1.9.0/conf
```

将flume-env.sh.template文件复制一份，并重命名为flume-env.sh

```shell
cp flume-env.sh.template flume-env.sh
```

在flume-env.sh文件中写入以下内容：

```sh
JAVA_HOME = /usr
```

**④ 验证**

在flume-1.9.0目录下执行以下命令

```shell
./bin/flume-ng version
```

若看到flume的版本号，则证明flume已成功安装

![image-20210331211502659](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210331211502659.png)

成功！

##### (2) Thrift

版本：thrift-0.14.0

**① 下载**

地址：https://mirrors.bfsu.edu.cn/apache/thrift/0.14.1/thrift-0.14.1.tar.gz

**② 解压**

在压缩包的目录下解压

```shell
tar -zxvf thrift-0.14.1.tar.gz
```

将解压文件移动到thrift-0.14.1目录下

```shell
mv thrift-0.14.1 thrift-0.14.1
```

**③ 安装依赖**

```shell
sudo apt-get install automake bison flex g++ git libboost-all-dev libevent-dev libssl-dev libtool make pkg-config
```

**④ 安装Thrift**

进入thrift-0.14.1目录下，依次输入以下命令

```shell
./configure
```

```shell
make
```

```shell
sudo make install
```

**⑤ 验证**

```shell
thrift -version
```

![image-20210331204512163](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210331204512163.png)

成功！

##### (3) Kafka

版本：kafka-2.13-2.6.1

**① 下载**

从官网上将安装包下载到虚拟机

下载地址：http://kafka.apache.org/downloads

**② 解压**

在解压包目录下

```shell
tar -zxvf kafka_2.13-2.6.1.tgz
```

将解压文件移到kafka_2.13-2.6.1目录下

```shell
mv kafka_2.13-2.6.1 kafka-2.13-2.6.1
```



**③ 启动zookeeper**

修改配置

在kafka-2.13.2.6.1/config目录下修改zookeeper.properties

```html
clientPort=2281
```

![image-20210402093650330](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402093650330.png)

启动

在kafka-2.13-2.6.1目录下输入以下命令（参数-daemon表示后台守护运行）

```shell
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
```

验证：

方法1：jps命令

```shell
jps
```

![image-20210401101613276](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210401101613276.png)

有QuorumPeerMain则启动成功

方法2：ps命令加上正则表达式

```shell
ps aux | grep 'zookeeper'
```

![image-20210401101641171](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210401101641171.png)

有返回则启动成功

**④ 启动三个Kafka服务器**

因为config里面只有一个server.properties，但我们需要启动三个kafka服务器，所以需要做如下配置：

将server.properties文件复制三份，分别命名为server0.properties、server1.properties和server2.properties

```shell
cp config/server.properties config/server0.properties
cp config/server.properties config/server1.properties
cp config/server.properties config/server2.properties
```

![image-20210401105727641](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210401105727641.png)

并对他们做出如下修改

server0.properties:

```html
broker.id=0
listeners=PLAINTEXT://:9092
advertised.listeners=PLAINTEXT://fly:9092
log.dir=/tmp/kafka-logs-0
```

![image-20210402093728053](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402093728053.png)

![image-20210402093750244](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402093750244.png)

![image-20210402093810483](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402093810483.png)

server1.properties(截图跟上面的差不多，就不截图了):

```html
broker.id=1
listeners=PLAINTEXT://:9093
advertised.listeners=PLAINTEXT://fly:9093
log.dir=/tmp/kafka-logs-1
```

server2.properties(同上):

```shell
broker.id=2
listeners=PLAINTEXT://:9094
advertised.listeners=PLAINTEXT://fly:9094
log.dir=/tmp/kafka-logs-2
```

启动三个broker节点

```shell
bin/kafka-server-start.sh config/server0.properties
bin/kafka-server-start.sh config/server1.properties
bin/kafka-server-start.sh config/server2.properties
```

验证：

使用jps命令查看运行情况

```shell
jps
```

![image-20210401103650299](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210401103650299.png)

可以看到三个kafka服务器已启动

##### (4) HBase

版本：apache-hbase-2.3.4

**① 下载**

地址：https://hadoop.apache.org/releases.html

注意，需下载与Hadoop兼容的版本。Hadoop与HBase版本兼容性在下列地址中查询

http://hbase.apache.org/book.html#hadoop

官方推荐使用HBase2.3.4与Hadoop2.10.1集成

**② 解压**

执行tar命令，解压下载的hbase-2.3.4-bin.tar.gz压缩包文件

```shell
tar -zxvf hbase-2.3.4-bin.tar.gz
```

**③ 修改配置文件**

1、在hbase-2.3.4/conf目录下，修改hbase-env.sh文件的以下内容

```html
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HBASE_CLASSPATH=~/HBase/hbase-2.3.4/conf
export HBASE_MANAGES_ZK=true
```

![image-20210401191504524](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210401191504524.png)

2、在hbase-2.3.4/conf目录下，修改hbase-site.xml文件

将属性hbase.cluter.distributed设置为true

```html
<configuration>
   	<property>
    	<name>hbase.rootdir</name>
    	<value>hdfs://fly:9000/hbase</value>
  	</property>
    <property>
        <name>hbase.cluster.distributed</name>
        <value>true</value>
    </property>
</configuration>
```

3、修改regionservers文件

```html
fly
```



**④ 启动**

启动HBase之前，需先启动Hadoop

进入HBase安装的目录，执行以下命令启动HBase

```shell
./bin/start-hbase.sh
```



**⑤ 使用jps命令查看HBase启动情况**

以伪分布式方式启动HBase，会在jps命令中看到三个进程HMaster, HRegionServer, HQuorumPeer

```shell
jps
```

![image-20210401183735463](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210401183735463.png)

安装成功



#### 2、启动HBase，并创建HBase表（利用shell）

**① 进入交互式shell命令行**

```shell
./bin/hbase shell
```

![image-20210401202018980](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210401202018980.png)

**② 创建一个新的命名空间，‘bigdata'**

```shell
create_namespace 'bigdata'
```



![image-20210402091724109](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402091724109.png)

**③ 创建HBase表**

名："HBase_Orders"

两个列族，"Order Detail" 与 "Transaction"

命令如下

```shell
create 'bigdata:HBase_Orders','Order Detail','Transaction'
```

![image-20210402092304797](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402092304797.png)

#### 3、启动三个Kafka服务器

3.1、3.2、3.3在前面安装Kafka的步骤已经说过一次了，这里再简单说一次

##### 3.1 启动Kafka自带的Zookeeper

在kafka-2.13.2.6.1/config目录下修改zookeeper.properties

```html
clientPort=2281
```

![image-20210402093650330](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402093650330.png)

启动

参数-daemon表示后台守护运行

不加-daemon的话就需要新开一个终端，效果一样

```shell
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
```

![image-20210402100157287](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402100157287.png)

![image-20210402101341860](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402101341860.png)

##### 3.2 修改conf的server文件

将server.properties文件复制三份，分别命名为server0.properties、server1.properties和server2.properties

```shell
cp config/server.properties config/server0.properties
cp config/server.properties config/server1.properties
cp config/server.properties config/server2.properties
```

![image-20210401105727641](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210401105727641.png)

并对他们做出如下修改

server0.properties:

```html
broker.id=0
listeners=PLAINTEXT://:9092
advertised.listeners=PLAINTEXT://fly:9092
log.dir=/tmp/kafka-logs-0
```

![image-20210402093728053](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402093728053.png)

![image-20210402093750244](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402093750244.png)

![image-20210402093810483](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402093810483.png)

server1.properties(截图跟上面的差不多，就不截图了):

```html
broker.id=1
listeners=PLAINTEXT://:9093
advertised.listeners=PLAINTEXT://fly:9093
log.dir=/tmp/kafka-logs-1
```

server2.properties(同上):

```shell
broker.id=2
listeners=PLAINTEXT://:9094
advertised.listeners=PLAINTEXT://fly:9094
log.dir=/tmp/kafka-logs-2
```

##### 3.3 启动三个Kafka服务器

启动三个broker节点

```shell
bin/kafka-server-start.sh -daemon config/server0.properties
bin/kafka-server-start.sh -daemon config/server1.properties
bin/kafka-server-start.sh -daemon config/server2.properties
```

![image-20210402101538155](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402101538155.png)

![image-20210402101625406](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402101625406.png)

启动成功！

##### 3.4 创建一个名为"Kafka_Orders"的Topic

一个分区和三个副本

```shell
bin/kafka-topics.sh --create --zookeeper fly:2281 --replication-factor 3 --partitions 1 --topic Kafka_Orders
```

![image-20210402103430491](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402103430491.png)

创建成功

**验证：**

```shell
bin/kafka-topics.sh --list --zookeeper fly:2281
```

![image-20210402103525057](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210402103525057.png)

#### 4、编写Kafka消费者

##### 4.1 连接Kafka服务器

```java
public kafka_consumer(){
        Properties props=new Properties();
        // 监听端口
        props.put("bootstrap.servers","fly:9094");
        // 指定消费者所属群组
        props.put("group.id","test-consumer-group");
        props.put("enable.auto.commit","true");
        props.put("auto.commit.interval.ms","1000");
        props.put("session.timeout.ms","30000");
        props.put("auto.offset.reset","earliest");
    props.put("key.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
        consumer=new KafkaConsumer<String,String>(props);
    }
```

##### 4.2 连接HBase服务器

```java
Configuration conf = HBaseConfiguration.create();
conf.set("hbase.rootdir","hdfs://fly:9000/hbase");
conf.set("hbase.zookeeper.property.dataDir","/home/r52125/HBase/hbase-2.3.4/zookeeper");
conf.set("hbase.zookeeper.quorum","fly");
conf.set("hbase.cluster.distributed","true");
Connection connection = ConnectionFactory.createConnection(conf);
```

##### 4.3 不断读取Kafka消息队列中的事件

```java
while(true){        // 消息轮询
    // 100是超时时间，在改时间内poll会等待服务器返回数据
    ConsumerRecords<String,String> records=consumer.poll(100);
    // poll返回一个纪录列表
    // 每条记录都包含了记录的键值对
    for(ConsumerRecord<String,String> record:records){
        System.out.println("Get message: key=[" +record.key()+ "], message=[" +record.value() + "]" );
        col = record.key();
        value = record.value();
        //System.out.println("col: "+col+" value: "+ value);
        if (col != null){
            try {
                putData.send_data(col, value);
            }
            catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}
```

##### 4.4 对于每个事件，将其转化为HBase Put类的形式，并提交到HBase服务器中

```java
// 使用Connection类的getTable()方法获取HTable类对象
HTable table = (HTable) connection.getTable(TableName.valueOf("bigdata:HBase_Orders"));
// 声明一个Put类对象，并初始化其行键
Put put=new Put(key[0].getBytes());
// 使用put类的addColumn()方法加入将写入数据
// System.out.println(key[0] + key[1]);
if (key[1].equals("Order Detail"))
    put.addColumn("Order Detail".getBytes(), key[1].getBytes(), value.getBytes());
else if(key[1].equals("Transaction"))
    put.addColumn("Transaction".getBytes(), key[1].getBytes(), value.getBytes());
// 使用HTable类的put()方法将数据写入HBase表中
table.put(put);
table.close();
connection.close();
```

#### 5、启动Flume

在本次实验中，Source 使用 HTTP Source，Sink 使用 Kafka Sink

跟安装相关的一些配置前面已经有写了，这里再简单讲一下

**① 安装配置**

进入配置文件目录下

```shell
cd flume-1.9.0/conf
```

将flume-env.sh.template文件复制一份，并重命名为flume-env.sh

```shell
cp flume-env.sh.template flume-env.sh
```

在flume-env.sh文件中写入以下内容：

```sh
JAVA_HOME = /usr/lib/jvm/java-8-openjdk-amd64
```

 **② 安装验证**

在flume-1.9.0目录下执行以下命令

```shell
./bin/flume-ng version
```

若看到flume的版本号，则证明flume已成功安装

![image-20210331211502659](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210331211502659.png)

**③ 其他配置**

复制 flume-conf.properties.template 文件并命名为 flume-kafka-hbase.conf，修改其中 Source、Channel、Sink 的参数

**(I) 复制文件**



```shell
cp flume-conf.properties.template flume-kafka-hbase.conf
```

**(II) 修改Source配置**

![image-20210404162648734](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210404162648734.png)

**(III) 修改Channel配置**

![image-20210415094047983](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210415094047983.png)

**(IV) 修改Sink配置**

![image-20210415094125241](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210415094125241.png)

**(V) 连接sources、sinks、channels**

![image-20210403120005315](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210403120005315.png)

![image-20210403115934302](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210403115934302.png)

**(VI) 运行所编写的flume-kafka-hbase.conf，启动Flume服务器进行数据收集**

启动命令:

```shell
./bin/flume-ng agent --name agent --conf ./conf --conf-file ./conf/flume-kafka-hbase.conf -Dflume.root.logger=DEBUG,console
```

![image-20210403120501820](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210403120501820.png)

**不解：**这里的DEBUG换成INFO，也可以，不知道这个参数的值有什么用处

**验证：**

**① 测试flume是否可以正常接收http信息**

新开一个终端，输入以下测试命令

```shell
curl -X POST -d'[{"headers":{"h1":"v1","h2":"v2"},"body":"hello body"}]'  http://fly:44444
```

![image-20210404162745242](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210404162745242.png)

看flume的控制台输出，如下

![image-20210404162844925](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210404162844925.png)

明显看到已经接收到信息，内容为"hello body"

**结论：**Flume正常开启，并且可以正常进行数据收集

**② 测试flume和kafka能否连通**

新开一个终端，运行Kafka_comsumer，只运行接收的那部分代码

```shell
java -jar Kafka_comsumer.jar
```

flume的启动和输入的测试命令与上面相同

结果如下图所示

![image-20210415095650076](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210415095650076.png)

**结论：flume和kafka可以正常连接**

#### 6、启动具有数据生成功能的服务器

​	运行所提供的服务器 generatorData.py，开始产生数据并发送到 Flume 进行数据收集。

​	generatorData.py 产生的数据如下图所示，该服务器会自动将产生的每一条数据中 “headers”作为报文头字段（也就是 HTTP 报文中的“header”），将“body”作为报文内容字段（也就是 HTTP 报文中的“data”）

![image-20210404170615033](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210404170615033.png)

**测试：**

与上一点的测试类似，只是把手动输入信息改成用python文件输入

执行python文件命令:

```shell
python3 generatorData.v2.py -h fly -p 44444
```

![image-20210415100719096](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210415100719096.png)

![image-20210415151306048](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210415151306048.png)

发现一点小错误，所有的数据都放在第一行了，需要改动一下代码。

更改行键后，再次运行，结果如下：

![image-20210418215500121](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210418215500121.png)

#### 7、查看HBase表

在~/HBase/hbase目录下，进入shell命令操作

```shell
./bin/hbase shell
```

查看自己的HBase表

```shell
scan 'bigdata:HBase_Orders'
```

![image-20210418215513596](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210418215513596.png)

### 四、选做内容

#### 1、使用Java API 替代 Java shell 操作

##### (1) 创建一个“HBase_Orders”表

java代码如下

![image-20210415162824617](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210415162824617.png)

打包成jar后，在目录下运行

```shell
java -jar create_Table.jar
```

![image-20210415173123115](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210415173123115.png)

执行代码前后的变化：
![image-20210415173150083](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210415173150083.png)

##### (2) 定时查看“HBase_Orders”表内的数据量，完成最简单的统计

```shell
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.TableName;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter;

import java.io.IOException;

public class count_Table {
    public static void main(String[] args) throws IOException, InterruptedException {
        Configuration conf = HBaseConfiguration.create();
        conf.set("hbase.rootdir","hdfs://fly:9000/hbase");
        conf.set("hbase.zookeeper.property.dataDir","/home/r52125/HBase/hbase-2.3.4/zookeeper");
        conf.set("hbase.zookeeper.quorum","fly");
        conf.set("hbase.cluster.distributed","true");
        Connection connection = ConnectionFactory.createConnection(conf);
        // 使用Connection类的getTable()方法获取HTable类对象
        while(true) {
            HTable table = (HTable) connection.getTable(TableName.valueOf("bigdata:HBase_Orders"));
            Scan scan = new Scan("00000".getBytes());
            scan.setFilter(new FirstKeyOnlyFilter());
            ResultScanner resultScanner = table.getScanner(scan);
            long rowCount = 0;
            for (Result result : resultScanner) {
                rowCount += result.size();
            }
            System.out.println("rowCount-->" + rowCount);
            Thread.sleep(5000);
        }
    }
}

```

![image-20210415212240215](C:\Users\win10\AppData\Roaming\Typora\typora-user-images\image-20210415212240215.png)

每隔5秒查看一次HBase_Orders表中的数据量

这里因为我没有对HBase表进行任何操作，所以每次都是7

输出最好再加入时间，这个也比较容易，我就不加了

#### 2、使用序列化技术